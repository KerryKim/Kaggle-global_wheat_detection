{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YoloV5 [train] 예제\n",
    "# https://www.kaggle.com/orkatz2/yolov5-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "/ : 루트 (가장 최상의 디렉토리로 이동한다.)\n",
    "./ : 현재 위치 (파일의 현재 디렉토리를 의미한다.)\n",
    "../ : 현재 위치의 상단 폴더 (상위 디렉토리로 이동한다.)\n",
    "\n",
    "ex) index.php가 C:\\index\\a에 위치한다면,\n",
    "      여기서 / 는 C:\n",
    "               ./ 는 a\n",
    "              ../ 는 index라는 것.\n",
    "    만약 두단계 상위 디렉토리로 이동하려면 '../../' 이렇게 쓰면 된다.\n",
    "'''\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/train.csv')\n",
    "bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "    df[column] = bboxs[:,i]\n",
    "df.drop(columns=['bbox'], inplace=True)\n",
    "df['x_center'] = df['x'] + df['w']/2\n",
    "df['y_center'] = df['y'] + df['h']/2\n",
    "df['classes'] = 0\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh\n",
    "df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>x_center</th>\n",
       "      <th>y_center</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>834.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>862.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>226.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>377.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>834.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>888.5</td>\n",
       "      <td>148.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6ab77fd7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>202.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id      x      y      w      h  x_center  y_center  classes\n",
       "0  b6ab77fd7  834.0  222.0   56.0   36.0     862.0     240.0        0\n",
       "1  b6ab77fd7  226.0  548.0  130.0   58.0     291.0     577.0        0\n",
       "2  b6ab77fd7  377.0  504.0   74.0  160.0     414.0     584.0        0\n",
       "3  b6ab77fd7  834.0   95.0  109.0  107.0     888.5     148.5        0\n",
       "4  b6ab77fd7   26.0  144.0  124.0  117.0      88.0     202.5        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = list(set(df.image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7744e031610949f3b2e2010f4ba6a93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3373.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source = 'train'\n",
    "if True:\n",
    "    for fold in [0]:\n",
    "        val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]    # 전체 학습데이터 중 5분의 1을 검증데이터로 나누는 부분인듯\n",
    "        for name,mini in tqdm(df.groupby('image_id')):\n",
    "            if name in val_index:\n",
    "                path2save = 'val2017/'\n",
    "            else:\n",
    "                path2save = 'train2017/'\n",
    "            \n",
    "            # 폴더생성\n",
    "            if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "            \n",
    "            with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                row = row/1024\n",
    "                row = row.astype(str)\n",
    "                for j in range(len(row)):\n",
    "                    text = ' '.join(row[j])\n",
    "                    f.write(text)\n",
    "                    f.write(\"\\n\")\n",
    "            \n",
    "            # 폴더생성\n",
    "            if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "            \n",
    "            # 생성한 폴더에 이미지를 복사한다.\n",
    "            sh.copy(\"./data/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex\n",
      "{'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n",
      "Namespace(adam=False, batch_size=1, bucket='', cache_images=False, cfg='./yolov5/input/configYolo5/yolov5x.yaml', data='./yolov5/input/configYolo5/wheat0.yaml', device='', epochs=1, evolve=False, img_size=[1024], multi_scale=False, name='yolov5x_fold0', noautoanchor=False, nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='')\n",
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2070 SUPER', total_memory=7974MB)\n",
      "\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "\n",
      "              from  n    params  module                                  arguments                     \n",
      "  0             -1  1      8800  models.common.Focus                     [3, 80, 3]                    \n",
      "  1             -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
      "  2             -1  4    513920  models.common.Bottleneck                [160, 160]                    \n",
      "  3             -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
      "  4             -1  1   3311680  models.common.BottleneckCSP             [320, 320, 12]                \n",
      "  5             -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
      "  6             -1  1  13228160  models.common.BottleneckCSP             [640, 640, 12]                \n",
      "  7             -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
      "  8             -1  1   4099840  models.common.SPP                       [1280, 1280, [5, 9, 13]]      \n",
      "  9             -1  1  36481280  models.common.BottleneckCSP             [1280, 1280, 8]               \n",
      " 10             -1  1  20087040  models.common.BottleneckCSP             [1280, 1280, 4, False]        \n",
      " 11             -1  1     23058  torch.nn.modules.conv.Conv2d            [1280, 18, 1, 1]              \n",
      " 12             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 13        [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 14             -1  1   1230080  models.common.Conv                      [1920, 640, 1, 1]             \n",
      " 15             -1  1   5025920  models.common.BottleneckCSP             [640, 640, 4, False]          \n",
      " 16             -1  1     11538  torch.nn.modules.conv.Conv2d            [640, 18, 1, 1]               \n",
      " 17             -2  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18        [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 19             -1  1    307840  models.common.Conv                      [960, 320, 1, 1]              \n",
      " 20             -1  1   1258560  models.common.BottleneckCSP             [320, 320, 4, False]          \n",
      " 21             -1  1      5778  torch.nn.modules.conv.Conv2d            [320, 18, 1, 1]               \n",
      " 22   [-1, 16, 11]  1         0  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]\n",
      "Model Summary: 381 layers, 9.53903e+07 parameters, 9.53903e+07 gradients, 169.1 GFLOPS\n",
      "\n",
      "Optimizer groups: 126 .bias, 132 conv.weight, 123 other\n",
      "Caching labels convertor/fold0/labels/train2017.npy (2699 found, 0 missing, 0 em\n",
      "Caching labels convertor/fold0/labels/val2017 (674 found, 0 missing, 0 empty, 0 \n",
      "\n",
      "Analyzing anchors... Best Possible Recall (BPR) = 0.9992\n",
      "Image sizes 1024 train, 1024 test\n",
      "Using 0 dataloader workers\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n",
      "  0%|                                                  | 0/2699 [00:00<?, ?it/s]/home/kerrykim/anaconda3/envs/global_wheat_detection/lib/python3.7/site-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  FutureWarning)\n",
      "       0/0     4.63G   0.08647    0.1883         0    0.2747       111      1024\n",
      "               Class      Images     Targets           P           R      mAP@.5/home/kerrykim/jupyter_notebook/8. wheat_detection/yolov5/test.py:161: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  ti = (cls == tcls_tensor).nonzero().view(-1)  # prediction indices\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all         674    2.91e+04      0.0878       0.532      0.0619      0.0139\n",
      "Optimizer stripped from weights/last_yolov5x_fold0.pt\n",
      "1 epochs completed in 0.297 hours.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "cfg?\n",
    "cfg 파일은 신경망의 구조(layer 개수, 입력 데이터의 차원 등)를 명시한 파일이고 weights 파일은 실제로 학습된 신경망의 weight 값들을 저장한 것이다.\n",
    "cfg = config = configuration, 구성\n",
    "\n",
    "Apex?\n",
    "NVIDIA APEX, 엔비디아에서 제공하는 더 빠른 학습방법에 대한 패키지\n",
    "https://cvml.tistory.com/8\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "!python ./yolov5/train.py --img 1024 --batch 1 --epochs 1 --data './yolov5/input/configYolo5/wheat0.yaml' --cfg './yolov5/input/configYolo5/yolov5x.yaml' --name yolov5x_fold0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오픈소스코드에는 !python 라인에 따옴표가 없었다.\n",
    "# YoloV5에는 Cutmix, mosaic, brightness-contrast 등 최신 데이터 증강기법이 기적용되어 있어 또 할 필요는 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Be careful that this command index = list(set(df.image_id)) is not sorted and we may get different order (e.g. I got different order when I run with Colab and Kaggle), so fold=0 or 1 may be does not matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:global_wheat_detection]",
   "language": "python",
   "name": "conda-env-global_wheat_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
