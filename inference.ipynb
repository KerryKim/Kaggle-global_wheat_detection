{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook has version issue\n",
    "# If you don't downgrade torch and torchvision, you can get runtime cuda error.\n",
    "# ex> \"runtimeerror: gather_out_cuda(): expected dtype int64 for index\"\n",
    "\n",
    "# !pip install torch==1.5.0\n",
    "# !pip install torchvision==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/kerrykim/jupyter_notebook/008.wheat_detection/efficientdet')\n",
    "sys.path.insert(0, '/home/kerrykim/jupyter_notebook/008.wheat_detection/omegaconf')\n",
    "sys.path.insert(0, '/home/kerrykim/jupyter_notebook/008.wheat_detection/weightedboxesfusion')\n",
    "                \n",
    "from weightedboxesfusion.ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "from efficientdet.effdet import get_efficientdet_config, EfficientDet, DetBenchEval\n",
    "from efficientdet.effdet.efficientdet import HeadNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configurations\n",
    "class CFG:\n",
    "    mode = 'test'\n",
    "    seed = 42\n",
    "    print_freq = 30\n",
    "\n",
    "    n_class = 5\n",
    "\n",
    "    img_x = 512\n",
    "    img_y = 512\n",
    "\n",
    "    num_fold = 5\n",
    "    num_epoch = 50\n",
    "    batch_size = 2\n",
    "    num_workers = 2    # decide how many data upload to dataset for a batch\n",
    "                       # if n_workers 2, dataloader works twice for a batch.\n",
    "                       # It has impact for cuda memory too\n",
    "\n",
    "    lr = 0.0002\n",
    "\n",
    "    max_grad_norm = 1000\n",
    "\n",
    "\n",
    "    data_dir = './data_origin/test'\n",
    "    ckpt_dir = './checkpoint/final_f1_ep3_bt2_date05.03-15:06.pth'\n",
    "    result_dir = './result'\n",
    "    log_dir = './log'\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        lst_input = os.listdir(self.data_dir)\n",
    "        self.lst_input = lst_input\n",
    "        self.image_id = [image_id.split('/')[-1][:-4] for image_id in lst_input]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_id[index]\n",
    "        image = cv2.imread(os.path.join(self.data_dir, self.lst_input[index]), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        if self.transform:\n",
    "            sample = {'image' : image}\n",
    "            sample = self.transform(**sample)    # 이때까지 해왔던 입력방식은 cv2 이미지를 직접 입력, 여기선 numpy 로 입력\n",
    "            image = sample['image']\n",
    "\n",
    "        return image, image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(ckpt_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    # net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    # net.load_state_dict(checkpoint, strict=False) # strict=False 해주니까 된다.\n",
    "    net.load_state_dict(checkpoint)\n",
    "    \n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = (DetBenchEval(net, config)).to(device)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_test():\n",
    "    return A.Compose([A.Resize(height=512, width=512, p=1.0), ToTensorV2(p=1.0)], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(loader_test, net, score_threshold=0.22):\n",
    "    net.eval()\n",
    "    pred = []\n",
    "\n",
    "    ##\n",
    "    for batch, (images, image_ids) in enumerate(loader_test, 1):\n",
    "        images = torch.stack(images)\n",
    "        images = images.to(device).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            det = net(images, torch.tensor([1]*images.shape[0]).float().cuda())\n",
    "            output = []\n",
    "            for i in range(images.shape[0]):\n",
    "                boxes = det[i].detach().cpu().numpy()[:,:4]\n",
    "                scores = det[i].detach().cpu().numpy()[:,4]\n",
    "                indexes = np.where(scores > score_threshold)[0]\n",
    "                boxes = boxes[indexes]\n",
    "                boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "                boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "                output.append({\n",
    "                    'boxes': boxes[indexes],\n",
    "                    'scores': scores[indexes],\n",
    "                })\n",
    "\n",
    "            output = [output]\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            boxes, scores, labels = run_wbf(output, image_index=i)\n",
    "            boxes = (boxes * 2).astype(np.int32).clip(min=0, max=1023)\n",
    "            image_id = image_ids[i]\n",
    "\n",
    "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "            tmp = {'image_id': image_id, 'PredictionString': format_prediction_string(boxes, scores)}\n",
    "\n",
    "            pred.append(tmp)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf(predictions, image_index, image_size=512, iou_thr=0.44, skip_box_thr=0.43, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction_string(boxes, scores):\n",
    "    pred_strings = []\n",
    "    for j in zip(scores, boxes):\n",
    "        pred_strings.append(\"{0:.4f} {1} {2} {3} {4}\".format(j[0], j[1][0], j[1][1], j[1][2], j[1][3]))\n",
    "    return \" \".join(pred_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    dataset_test = Dataset(data_dir=CFG.data_dir, transform=transform_test())\n",
    "    loader_test = DataLoader(dataset_test, batch_size=CFG.batch_size, shuffle=False, num_workers=8, drop_last=False, collate_fn=collate_fn, pin_memory=True)\n",
    "\n",
    "    net = load_net(CFG.ckpt_dir)\n",
    "    pred = test_one_epoch(loader_test, net)\n",
    "\n",
    "    submission = pd.DataFrame(pred, columns=['image_id', 'PredictionString'])\n",
    "    submission.to_csv('submission.csv',index=False)\n",
    "    # submission.to_csv(os.path.join(CFG.result_dir, 'submission.csv'))\n",
    "    \n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "if __name__ == \"__main__\":\n",
    "    if CFG.mode == \"test\":\n",
    "        submission = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb8d261a3</td>\n",
       "      <td>0.6393 304 168 109 199 0.6321 521 515 113 61 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51b3e36ab</td>\n",
       "      <td>0.6983 530 25 282 147 0.6416 462 7 89 152 0.61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cc3532ff6</td>\n",
       "      <td>0.6181 762 839 166 156 0.6172 478 571 122 145 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f5a1f0358</td>\n",
       "      <td>0.7107 933 431 90 192 0.6301 445 307 104 169 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2fd875eaa</td>\n",
       "      <td>0.6076 454 494 89 145 0.5600 0 0 107 73 0.5387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51f1be19e</td>\n",
       "      <td>0.5997 828 86 103 67 0.5851 828 292 109 177 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aac893a91</td>\n",
       "      <td>0.6340 561 541 121 187 0.5990 56 1 112 158 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>796707dd7</td>\n",
       "      <td>0.5668 942 80 79 92 0.5555 66 561 68 76 0.5520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>348a992bb</td>\n",
       "      <td>0.6582 584 433 139 119 0.6496 284 159 117 119 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53f253011</td>\n",
       "      <td>0.6612 615 94 137 155 0.6507 916 809 107 210 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                                   PredictionString\n",
       "0  cb8d261a3  0.6393 304 168 109 199 0.6321 521 515 113 61 0...\n",
       "1  51b3e36ab  0.6983 530 25 282 147 0.6416 462 7 89 152 0.61...\n",
       "2  cc3532ff6  0.6181 762 839 166 156 0.6172 478 571 122 145 ...\n",
       "3  f5a1f0358  0.7107 933 431 90 192 0.6301 445 307 104 169 0...\n",
       "4  2fd875eaa  0.6076 454 494 89 145 0.5600 0 0 107 73 0.5387...\n",
       "5  51f1be19e  0.5997 828 86 103 67 0.5851 828 292 109 177 0....\n",
       "6  aac893a91  0.6340 561 541 121 187 0.5990 56 1 112 158 0.5...\n",
       "7  796707dd7  0.5668 942 80 79 92 0.5555 66 561 68 76 0.5520...\n",
       "8  348a992bb  0.6582 584 433 139 119 0.6496 284 159 117 119 ...\n",
       "9  53f253011  0.6612 615 94 137 155 0.6507 916 809 107 210 0..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "766"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:global_wheat_detection]",
   "language": "python",
   "name": "conda-env-global_wheat_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
